\relax 
\newlabel{firstpage}{{}{1}}
\citation{dempster1977maximum,laird1978nonparametric}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\citation{wu1983convergence,boyles1983convergence,meng1994global}
\citation{nesterov1983method}
\citation{schmidt2017minimizing}
\citation{defazio2014saga}
\citation{lin2017generic}
\citation{shalev2014accelerated}
\citation{jamshidian1997acceleration,jamshidian1993conjugate,lange1995quasi,zhou2011quasi}
\citation{jamshidian1997acceleration}
\citation{lange1995quasi,jamshidian1997acceleration,jamshidian1993conjugate}
\citation{jamshidian1997acceleration}
\citation{jamshidian1997acceleration}
\citation{broyden1965class}
\citation{broyden1973local}
\citation{varadhan2008simple}
\citation{zhou2011quasi}
\citation{zhou2011quasi}
\citation{lange2008mm,zhou2015novel,xu2019power}
\citation{lee1999learning}
\citation{zou2008one}
\citation{luenberger1984linear,dennis1996numerical}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background: EM, MM, and Acceleration}{4}{}\protected@file@percent }
\newlabel{eq:descent}{{1}{4}}
\citation{zhou2011quasi}
\citation{jamshidian1997acceleration}
\citation{broyden1965class}
\citation{varadhan2008simple}
\newlabel{eq:QN_update}{{2}{5}}
\newlabel{eq:sec}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Existing MM Acceleration Schemes}{5}{}\protected@file@percent }
\newlabel{sec:qn}{{2.1}{5}}
\citation{varadhan2008simple}
\citation{zhou2011quasi}
\newlabel{eq:squarem_steplengths}{{4}{6}}
\citation{lange2016mm}
\newlabel{eq:ZALsecant}{{5}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {3}A novel Broyden quasi-Newton method}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Illustrative Example.}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison of secant approximations.}}{8}{}\protected@file@percent }
\newlabel{fig:secants}{{1}{8}}
\@writefile{toc}{\contentsline {paragraph}{Deriving the proposed method.}{9}{}\protected@file@percent }
\newlabel{eq:secant_approx}{{6}{9}}
\newlabel{eq:bqn_secant_condition}{{7}{9}}
\newlabel{eq:minimization}{{8}{9}}
\citation{varadhan2008simple}
\newlabel{eq:legrange_eq1}{{9}{10}}
\newlabel{eq:BFGS_update}{{11}{10}}
\citation{broyden1965class,pearson1969variable}
\@writefile{toc}{\contentsline {paragraph}{Intuition and relation to existing methods.}{11}{}\protected@file@percent }
\citation{shanno1978conjugate,nocedal1980updating,griewank1982partitioned}
\citation{liu1989limited}
\citation{fletcher2013practical}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}A limited memory variant for high-dimensional settings}{12}{}\protected@file@percent }
\citation{nocedal2006numerical}
\citation{varadhan2008simple}
\citation{lange2016mm}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Convergence}{13}{}\protected@file@percent }
\citation{broyden1973local}
\newlabel{lemma:lipchitz}{{1}{14}}
\newlabel{eq:lipchitz}{{12}{14}}
\citation{ortega2000iterative}
\citation{broyden1973local}
\newlabel{eq:ineq1}{{13}{15}}
\newlabel{eq:ineq2}{{14}{15}}
\newlabel{ass1}{{1}{15}}
\newlabel{ass2}{{2}{15}}
\newlabel{eq:jacobian_error}{{15}{15}}
\citation{broyden1973local}
\newlabel{th:convergence}{{1}{16}}
\newlabel{cor:superlinear_conv}{{1}{16}}
\newlabel{th:qnm_convergence}{{2}{16}}
\newlabel{eq:ineq3}{{16}{16}}
\citation{varadhan2008simple}
\citation{zhou2011quasi}
\newlabel{cor:q-superlinear}{{2}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results and Empirical Performance}{17}{}\protected@file@percent }
\newlabel{subsec:BFGSex}{{4}{17}}
\citation{lange2016mm}
\newdimen\statsocwidth@a\global\statsocwidth@a=475.42949pt \gdef\statsoc@gobble#1{}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Quadratic minimization of $f(\theta ) = \theta ^T A \theta /2 + b^T \theta $ for $100$ random starting points. }}{18}{}\protected@file@percent }
\newlabel{tab:quadratic}{{1}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Landweber's method for quadratic minimization}{18}{}\protected@file@percent }
\citation{lidwell1951observations}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Truncated Beta Binomial}{19}{}\protected@file@percent }
\newlabel{ex:trunc.beta.binom}{{4.2}{19}}
\citation{zhou2011quasi}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Quadratic minimization: number of function evaluations and runtime over $100$ random starting points. }}{20}{}\protected@file@percent }
\newlabel{fig:quad_boxplot}{{2}{20}}
\citation{zhou2011quasi}
\newdimen\statsocwidth@b\global\statsocwidth@b=318.3595pt \gdef\statsoc@gobble#1{}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  Truncated beta binomial: performance on Lidwell and Somerville data, from initial point $(\pi ,\alpha ) = (0.5, 1)$. }}{21}{}\protected@file@percent }
\newlabel{tab:beta_binom1}{{2}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Truncated beta binomial: ascent paths of peer methods on the Lidwell and Somerville household incidence data in a truncated beta binomial model, with optimum marked in red.}}{22}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {MM}}}{22}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {BQN, $q=1$}}}{22}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {BQN, $q=2$}}}{22}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {L-BQN}}}{22}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {SQUAREM-3}}}{22}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {ZAL, $q=1$}}}{22}{}\protected@file@percent }
\newlabel{fig:beta-contour}{{3}{22}}
\citation{zhou2011quasi}
\citation{hestenes1951solutions}
\citation{zhou2011quasi}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Generalized eigenvalues}{23}{}\protected@file@percent }
\newlabel{ex:gen.eigen}{{4.3}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Generalized eigenvalues: objectives at convergence over $10$ restarts vs the time and number of F evaluations. }}{24}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Smallest Eigenvalue}}}{24}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Smallest Eigenvalue}}}{24}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Largest Eigenvalue}}}{24}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Largest Eigenvalue}}}{24}{}\protected@file@percent }
\newlabel{fig:eigen-sp}{{4}{24}}
\citation{lange1989robust}
\citation{varadhan2008simple}
\citation{meng1997algorithm}
\newdimen\statsocwidth@c\global\statsocwidth@c=445.62358pt \gdef\statsoc@gobble#1{}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces  Generalized eigenvalues: number of $F(x)$ evaluations, runtime, and eigenvalues at convergence.}}{25}{}\protected@file@percent }
\newlabel{tab:gen_eigen}{{3}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Multivariate t-distribution}{25}{}\protected@file@percent }
\newlabel{ex:multi.t.distr}{{4.4}{25}}
\citation{meng1997algorithm}
\citation{meng1997algorithm}
\citation{zhou2011quasi}
\citation{varadhan2008simple,zhou2011quasi}
\newdimen\statsocwidth@d\global\statsocwidth@d=267.66495pt \gdef\statsoc@gobble#1{}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Multivariate t-distribution: maximum likelihood estimation of a 25-dimensional multivariate t-distribution. }}{26}{}\protected@file@percent }
\newlabel{tab:t-dist}{{4}{26}}
\citation{lange1995quasi,heiser1995convergent,lange2000optimization}
\citation{liu1989limited}
\citation{nocedal2006numerical}
\citation{varadhan2008simple}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{27}{}\protected@file@percent }
\bibstyle{rss}
\bibdata{example}
\bibcite{boyles1983convergence}{{1}{1983}{{Boyles}}{{}}}
\bibcite{broyden1965class}{{2}{1965}{{Broyden}}{{}}}
\bibcite{broyden1973local}{{3}{1973}{{Broyden et~al.}}{{Broyden, Dennis~Jr and Mor{\'e}}}}
\bibcite{defazio2014saga}{{4}{2014}{{Defazio et~al.}}{{Defazio, Bach and Lacoste-Julien}}}
\bibcite{dempster1977maximum}{{5}{1977}{{Dempster et~al.}}{{Dempster, Laird and Rubin}}}
\bibcite{dennis1996numerical}{{6}{1996}{{Dennis~Jr and Schnabel}}{{}}}
\bibcite{fletcher2013practical}{{7}{2013}{{Fletcher}}{{}}}
\bibcite{griewank1982partitioned}{{8}{1982}{{Griewank and Toint}}{{}}}
\bibcite{heiser1995convergent}{{9}{1995}{{Heiser}}{{}}}
\bibcite{hestenes1951solutions}{{10}{1951}{{Hestenes and Karush}}{{}}}
\bibcite{jamshidian1993conjugate}{{11}{1993}{{Jamshidian and Jennrich}}{{}}}
\bibcite{jamshidian1997acceleration}{{12}{1997}{{Jamshidian and Jennrich}}{{}}}
\bibcite{laird1978nonparametric}{{13}{1978}{{Laird}}{{}}}
\bibcite{lange1995quasi}{{14}{1995}{{Lange}}{{}}}
\bibcite{lange2016mm}{{15}{2016}{{Lange}}{{}}}
\bibcite{lange2000optimization}{{16}{2000}{{Lange et~al.}}{{Lange, Hunter and Yang}}}
\bibcite{lange2008mm}{{17}{2008}{{Lange and Wu}}{{}}}
\bibcite{lange1989robust}{{18}{1989}{{Lange et~al.}}{{Lange, Little and Taylor}}}
\bibcite{lee1999learning}{{19}{1999}{{Lee and Seung}}{{}}}
\bibcite{lidwell1951observations}{{20}{1951}{{Lidwell and Sommerville}}{{}}}
\bibcite{lin2017generic}{{21}{2017}{{Lin et~al.}}{{Lin, Mairal and Harchaoui}}}
\bibcite{liu1989limited}{{22}{1989}{{Liu and Nocedal}}{{}}}
\bibcite{luenberger1984linear}{{23}{1984}{{Luenberger et~al.}}{{Luenberger, Ye et~al.}}}
\bibcite{meng1994global}{{24}{1994}{{Meng and Rubin}}{{}}}
\bibcite{meng1997algorithm}{{25}{1997}{{Meng and Van~Dyk}}{{}}}
\bibcite{nesterov1983method}{{26}{1983}{{Nesterov}}{{}}}
\bibcite{nocedal1980updating}{{27}{1980}{{Nocedal}}{{}}}
\bibcite{nocedal2006numerical}{{28}{2006}{{Nocedal and Wright}}{{}}}
\bibcite{ortega2000iterative}{{29}{2000}{{Ortega and Rheinboldt}}{{}}}
\bibcite{pearson1969variable}{{30}{1969}{{Pearson}}{{}}}
\bibcite{schmidt2017minimizing}{{31}{2017}{{Schmidt et~al.}}{{Schmidt, Le~Roux and Bach}}}
\bibcite{shalev2014accelerated}{{32}{2014}{{Shalev-Shwartz and Zhang}}{{}}}
\bibcite{shanno1978conjugate}{{33}{1978}{{Shanno}}{{}}}
\bibcite{varadhan2008simple}{{34}{2008}{{Varadhan and Roland}}{{}}}
\bibcite{wu1983convergence}{{35}{1983}{{Wu}}{{}}}
\bibcite{xu2019power}{{36}{2019}{{Xu and Lange}}{{}}}
\bibcite{zhou2011quasi}{{37}{2011}{{Zhou et~al.}}{{Zhou, Alexander and Lange}}}
\bibcite{zhou2015novel}{{38}{2015}{{Zhou et~al.}}{{Zhou, Hu, Song and Yu}}}
\bibcite{zou2008one}{{39}{2008}{{Zou and Li}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Appendix}{31}{}\protected@file@percent }
\newlabel{sec:appendix}{{6}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Proof of Theorem\nobreakspace  {}1\hbox {}}{31}{}\protected@file@percent }
\newlabel{eq:epsilon_delta1}{{17}{32}}
\newlabel{eq:epsilon_delta2}{{18}{32}}
\citation{broyden1973local}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Proof of Theorem 2}{33}{}\protected@file@percent }
\newlabel{eq:MEM}{{19}{33}}
\newlabel{lemma:MEM}{{2}{33}}
\newlabel{eq:lemma2_condition}{{20}{33}}
\newlabel{eq:ineq4}{{21}{34}}
\newlabel{eq:uv_ineq}{{22b}{35}}
\newlabel{eq:beta_value}{{23b}{35}}
\newlabel{eq:H_ineq}{{24}{35}}
\newlabel{eq:H_error_bound}{{25}{36}}
\newlabel{eq:lim_(H-G'y)/(y)}{{26}{36}}
\citation{lidwell1951observations}
\newlabel{eq:G(F(x))_upperbound}{{27}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Examples}{37}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}Truncated Beta Binomial}{37}{}\protected@file@percent }
\newdimen\statsocwidth@e\global\statsocwidth@e=258.16164pt \gdef\statsoc@gobble#1{}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces The Lidwell and Somerville (1951) cold data on households of size $4$ and corresponding MLEs under the truncated beta-binomial model.}}{38}{}\protected@file@percent }
\newlabel{tab:bet_binom_data}{{5}{38}}
\newdimen\statsocwidth@f\global\statsocwidth@f=342.4012pt \gdef\statsoc@gobble#1{}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Truncated beta binomial: comparison of algorithms for the Lidwell and Somerville Data. The starting point is $(\pi ,\alpha ) = (0.5, 1)$, the stopping criterion is $\epsilon = 10^{-7}$, and the number of parameters is two.}}{39}{}\protected@file@percent }
\newlabel{tab:beta_binom2}{{6}{39}}
\newlabel{lastpage}{{}{39}}
\gdef \@abspage@last{39}
